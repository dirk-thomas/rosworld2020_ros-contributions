#!/usr/bin/env python3

"""
Generate the data used by the html page.

This uses:
* the static file `tooling-repos.yaml`,
* `data/repos.yaml` generated by `get-repos.py`, and
* `commits/**` generated by `get-commits.py`.
This generates the files `commits/**`.
"""

import math
import os
import sys
from collections import defaultdict
from collections import OrderedDict

import yaml

minimum_timestamp = 1325376000.0  # 2012/01/01


with open('tooling-repos.yaml', 'r') as h:
    repos = yaml.safe_load(h)

with open('data/repos.yaml', 'r') as h:
    repos.update(yaml.safe_load(h))

print(
    len(repos), 'repos with',
    sum(len(versions) for versions in repos.values()), 'branches')

authors = defaultdict(int)
urls = set()
commits_by_org = defaultdict(int)

print('Loading commits')
events = []
for url, versions in repos.items():
    owner_name, repo_name = url.split('/', 1)
    urls.add((owner_name, repo_name))

    # deduplicate commits on a per repo base
    repo_commits = []
    for branch, distros in versions.items():
        yaml_file = f'data/commits/{owner_name}/{repo_name}/{branch}.yaml'
        if not os.path.exists(yaml_file):
            continue
        print('.', end='')
        sys.stdout.flush()
        with open(yaml_file, 'r') as h:
            commits = yaml.safe_load(h)
        for commit in commits:
            if commit in repo_commits:
                continue
            repo_commits.append(commit)

    if not repo_commits:
        continue

    repo_commits.sort(key=lambda e: e['authoredDate'])

    # only generate a single event for multiple commits from the same author
    # within a period to reduce the event count
    repo_event_added = False
    last_events_by_author = {}
    for commit in repo_commits:
        if commit['authoredDate'] < minimum_timestamp:
            continue
        commits_by_org[owner_name] += 1

        # insert repo on first commit
        if not repo_event_added:
            events.append({
                'timestamp': commit['authoredDate'],
                'type': 'repo',
                'name': f'{owner_name}/{repo_name}',
            })
            repo_event_added = True

        grouping_duration = 28 * 24 * 60 * 60  # 4 weeks
        last_event_by_author = last_events_by_author.get(commit['author'])
        if (
            last_event_by_author and last_event_by_author['timestamp'] >
            commit['authoredDate'] - grouping_duration
        ):
            last_event_by_author['combined_commits'] += 1
            authors[commit['author']] += 1
            continue

        event = {
            'timestamp': commit['authoredDate'],
            'type': 'commit',
            'repo': f'{owner_name}/{repo_name}',
            'author': commit['author'] or 'Unknown',
            'avatar': commit['avatarUrl'],
            'combined_commits': 1,
        }
        last_events_by_author[commit['author']] = event
        events.append(event)
        authors[commit['author']] += 1
    # if len(events) > 10000:
    #     break
print()

print(len(authors), 'authors')
i = 0
for author, commits in sorted(authors.items(), key=lambda item: item[1], reverse=True):
    if author is None:
        continue
    print(author, commits)
    i += 1
    if i >= 10:
        break
print()

# distribute repos by org unit on a circle around the center
angle = 0.0
ranges = [(0.0, 2.0 * math.pi)]
for org, commit_count in sorted(commits_by_org.items(), key=lambda item: -item[1]):
    # print(org, commit_count, angle / math.pi * 180.0)
    # rotate circle by 45 deg to position large items in NW/NE/SW/SE
    rotated_angle = angle + math.pi / 4
    if rotated_angle > 2 * math.pi:
        rotated_angle -= 2 * math.pi
    for event in events:
        if event['type'] != 'repo' or not event['name'].startswith(f'{org}/'):
            continue
        event['angle'] = rotated_angle
    next_range = ranges.pop(0)
    angle = (next_range[1] - next_range[0]) / 2.0 + next_range[0]
    ranges += [
      (next_range[0], angle),
      (angle, next_range[1])]

print('Sorting', len(events), 'events')
events.sort(key=lambda e: e['timestamp'])

# generate one event per org
org_events = OrderedDict()
for i, event in enumerate(events):
    if event['type'] != 'repo':
        continue
    owner_name = event['name'].split('/', 1)[0]
    if owner_name in org_events:
        continue
    org_event = {
        'timestamp': event['timestamp'],
        'type': 'org',
        'name': owner_name,
        'angle': event['angle'],
        'commits': commits_by_org[owner_name],
    }
    org_events[owner_name] = (i, org_event)

# inject org events before the first repo in that org
offset = 0
for i, event in org_events.values():
    events[i + offset:i + offset] = [event]
    offset += 1

commit_count = 0
event_count = 0
with open('data.json', 'w') as h:
    h.write('{\n')
    h.write('    "events": [')

    for event in events:
        if event_count > 0:
            h.write(',')
        h.write('\n')
        h.write('        {')
        items = []
        for k, v in event.items():
            value = v if isinstance(v, float) else f'"{v}"'
            items.append(f'"{k}": {value}')
        h.write(', '.join(items))
        h.write('}')
        if event['type'] == 'commit':
            commit_count += event['combined_commits']
        event_count += 1

    h.write('\n')
    h.write('    ]\n')
    h.write('}\n')

print()
print(commit_count, 'commits grouped into', event_count, 'events')
